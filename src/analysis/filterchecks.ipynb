{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "002fea64-ac6a-41d8-acfe-dc6a409a948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import os, sys\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "p = os.path.abspath('../')\n",
    "sys.path.insert(1, p)\n",
    "\n",
    "from models.vgg_cif10 import VGG\n",
    "from models.wideresidual import WideResNet, WideBasic\n",
    "from models.orig_resnet import wide_resnet50_2\n",
    "\n",
    "import argparse\n",
    "import sklearn\n",
    "import sklearn.covariance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebda4b72-f11c-482e-9e55-12b27fab663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_path       = \"../data/attacks/run_1/cif10/wrn_28_10_10/fgsm/images\"\n",
    "# images_advs_path  = \"../data/attacks/run_1/cif10/wrn_28_10_10/fgsm/images_adv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d975ee32-82fb-4811-a31f-16a40f62cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images =      torch.load(images_path)[:1500]\n",
    "# images_advs = torch.load(images_advs_path)[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04353c2b-2c9b-42e5-949c-f14247ed6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_state_dict(checkpoint, keyword='net'):\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint[keyword].items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e4e77e-e2e4-4b73-aa18-efa75a662397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 28\n",
    "widen_factor = 10\n",
    "\n",
    "model = WideResNet(num_classes=10, block=WideBasic, depth=depth, widen_factor=widen_factor, preprocessing={})\n",
    "\n",
    "ckpt = torch.load(\"../submodules/pytorch-CelebAHQ/checkpoint/wideresnet_2810/wide_resnet_ckpt.pth\")\n",
    "new_state_dict = create_new_state_dict(ckpt)\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71641d81-565b-44cf-ab8d-6f5e4597e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786c5583-d19f-4366-97cb-62e5a3f6ab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0 ,dead:  False , e:  0.7074111728056349 , H_T:  0.8862397725366638\n",
      "i:  1 ,dead:  False , e:  0.8896211059801834 , H_T:  0.9508751836794926\n",
      "i:  2 ,dead:  False , e:  0.8474095304730729 , H_T:  0.9512742821563731\n",
      "i:  3 ,dead:  False , e:  0.7800455949864453 , H_T:  0.9512742821563731\n",
      "i:  4 ,dead:  False , e:  0.8082557090880014 , H_T:  0.9512742821563731\n",
      "i:  5 ,dead:  False , e:  0.9171634656429116 , H_T:  0.9512742821563731\n",
      "i:  6 ,dead:  False , e:  0.798194713324258 , H_T:  0.9512742821563731\n",
      "i:  7 ,dead:  False , e:  0.8290475259317821 , H_T:  0.9512742821563731\n",
      "i:  8 ,dead:  False , e:  0.7532617977394178 , H_T:  0.9512742821563731\n",
      "i:  9 ,dead:  False , e:  0.7066748205507543 , H_T:  0.9512872724113322\n",
      "i:  10 ,dead:  False , e:  0.8443278374196612 , H_T:  0.9512926194278255\n",
      "i:  11 ,dead:  False , e:  0.7999492660638517 , H_T:  0.9512926194278255\n",
      "i:  12 ,dead:  False , e:  0.7969917702934137 , H_T:  0.9512926194278255\n",
      "i:  13 ,dead:  False , e:  0.7985889366978531 , H_T:  0.9512926194278255\n",
      "i:  14 ,dead:  False , e:  0.78887748113057 , H_T:  0.9512926194278255\n",
      "i:  15 ,dead:  False , e:  0.7858568001901614 , H_T:  0.9512926194278255\n",
      "i:  16 ,dead:  False , e:  0.7721331923873401 , H_T:  0.9512926194278255\n",
      "i:  17 ,dead:  False , e:  0.7559727791157785 , H_T:  0.951294820334659\n",
      "i:  18 ,dead:  False , e:  0.8068557790878302 , H_T:  0.9512957262555302\n",
      "i:  19 ,dead:  False , e:  0.8062558780829376 , H_T:  0.9512957262555302\n",
      "i:  20 ,dead:  False , e:  0.7466533066282016 , H_T:  0.9512957262555302\n",
      "i:  21 ,dead:  False , e:  0.7752557562675694 , H_T:  0.9512957262555302\n",
      "i:  22 ,dead:  False , e:  0.625471321330447 , H_T:  0.9512957262555302\n",
      "i:  23 ,dead:  False , e:  0.5844251043458576 , H_T:  0.9512957262555302\n",
      "i:  24 ,dead:  True , e:  0.1388104743567733 , H_T:  0.9512957262555302\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(filter(lambda m: type(m) == torch.nn.Conv2d and m.kernel_size == (3, 3), model.modules())):\n",
    "    \n",
    "    w0 = m.weight.detach().cpu().numpy().copy()\n",
    "    w = (w0.reshape(-1, 9))\n",
    "\n",
    "    t = np.abs(w).max() / 100    \n",
    "    cache = np.ones_like(w)\n",
    "    cache[np.abs(w) < t] = 0\n",
    "    dead_mask = (cache.sum(axis=1) == 0)\n",
    "    \n",
    "    \n",
    "\n",
    "    with np.printoptions(edgeitems=1000):\n",
    "        dead_filter = np.where(dead_mask == True)[0]\n",
    "        # print(\"sparsity: \", dead_filter)\n",
    "\n",
    "    usv = np.linalg.svd(w - w.mean(axis=0), full_matrices=False, compute_uv=True)\n",
    "    u = usv[0]\n",
    "    s = usv[1]\n",
    "    v = s**2 / (w.shape[0]-1)\n",
    "\n",
    "    e = scipy.stats.entropy(v, base=10)\n",
    "    \n",
    "    def H_T(n):\n",
    "        L, x0, k, b = (1.2618047,2.30436435,0.88767525,-0.31050834)  # min distr.\n",
    "        return L / (1 + np.exp(-k * (np.log2(n) - x0))) + b\n",
    "    \n",
    "    dead = (e >= H_T(w.shape[0])) | (e < 0.5)\n",
    "    # print(\"dead_mask: \", )\n",
    "\n",
    "    print(\"i: \", i, \",dead: \", dead, \", e: \", e, \", H_T: \", H_T(w.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbd32e6c-e3aa-47a5-abe3-cb9ac3682d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2321390939.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_686/2321390939.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    t = np.abs(w).max() / 100\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(filter(lambda m: type(m) == torch.nn.Conv2d and m.kernel_size == (3, 3), model.modules())):\n",
    "    w0 = m.weight.detach().cpu().numpy().copy()\n",
    "    b0 = m.bias.detach().cpu().numpy().copy()\n",
    "    w = w0.copy()\n",
    "    \n",
    "    if i == 23: \n",
    "        t = np.abs(w).max() / 100    \n",
    "        cache = np.ones_like(w)\n",
    "        cache[np.abs(w) < t] = 0\n",
    "        dead_mask = (cache.reshape(w.shape[:2]+(9,)).sum(axis=2) == 0) # 640x640x9 = 9\n",
    "        dead_filter_tmp = np.sum(dead_mask, axis=0)\n",
    "        dead_filter = np.where(dead_filter_tmp > 300)[0]\n",
    "    \n",
    "    # dead_filter = np.where(dead_mask == True)\n",
    "    # print(i, \"\\t\",  w0.shape, \"\\t\",cache.shape , '\\t', dead_filter.shape)\n",
    "    print(i, \"\\t\",  w0.shape, \"\\t\", b0.shape)\n",
    "\n",
    "print(\"dead_mask\", dead_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c755090d-cfe7-49b0-a52f-0b44a634c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dead_filter_tmp, './../defenses/sparsity/dead_filter_tmp.pkl'  , pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "769efe04-4d25-4265-beee-16c58bd976ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dead_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd5baeb6-211e-49c3-b0e6-c1e0697f58ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([279, 281, 280, 273, 257, 255, 267, 281, 279, 355, 288, 281, 340,\n",
       "       259, 294, 259, 273, 314, 255, 254, 301, 268, 311, 329, 267, 281,\n",
       "       314, 265, 273, 285, 311, 328, 312, 284, 290, 270, 314, 338, 278,\n",
       "       296, 264, 270, 249, 276, 256, 256, 286, 297, 270, 261, 296, 296,\n",
       "       290, 271, 268, 282, 324, 280, 281, 292, 294, 281, 318, 333, 263,\n",
       "       318, 256, 300, 260, 290, 287, 262, 286, 267, 305, 285, 315, 264,\n",
       "       311, 279, 278, 270, 254, 269, 262, 269, 241, 306, 269, 231, 288,\n",
       "       284, 307, 299, 286, 271, 255, 276, 285, 318, 323, 327, 305, 278,\n",
       "       280, 254, 275, 296, 356, 281, 238, 246, 337, 330, 271, 311, 247,\n",
       "       286, 297, 257, 259, 268, 305, 298, 288, 293, 340, 299, 309, 301,\n",
       "       270, 263, 288, 319, 278, 295, 271, 303, 302, 320, 270, 318, 275,\n",
       "       245, 261, 274, 290, 271, 369, 342, 261, 259, 288, 309, 243, 368,\n",
       "       261, 349, 324, 313, 306, 275, 266, 277, 300, 302, 268, 315, 294,\n",
       "       284, 255, 262, 330, 266, 276, 287, 289, 282, 286, 325, 268, 307,\n",
       "       288, 313, 323, 286, 303, 320, 279, 296, 258, 371, 277, 332, 284,\n",
       "       313, 276, 301, 265, 241, 287, 280, 266, 285, 302, 259, 289, 281,\n",
       "       307, 266, 296, 314, 264, 261, 317, 304, 232, 280, 252, 249, 312,\n",
       "       244, 287, 289, 297, 241, 263, 276, 289, 269, 263, 266, 314, 263,\n",
       "       285, 271, 291, 261, 320, 272, 265, 268, 273, 305, 289, 291, 288,\n",
       "       277, 346, 293, 333, 291, 266, 286, 248, 259, 287, 306, 279, 262,\n",
       "       272, 272, 305, 300, 286, 316, 296, 253, 298, 269, 315, 310, 270,\n",
       "       275, 359, 299, 282, 297, 285, 252, 295, 262, 288, 269, 287, 246,\n",
       "       280, 275, 277, 258, 274, 280, 288, 268, 340, 289, 277, 250, 284,\n",
       "       266, 290, 265, 331, 291, 319, 299, 305, 302, 283, 351, 297, 286,\n",
       "       296, 262, 307, 283, 320, 268, 266, 293, 258, 252, 304, 298, 272,\n",
       "       293, 279, 360, 310, 325, 269, 315, 281, 264, 306, 303, 281, 301,\n",
       "       279, 256, 270, 289, 275, 285, 290, 326, 254, 306, 265, 266, 297,\n",
       "       368, 294, 296, 283, 243, 292, 290, 277, 274, 333, 273, 273, 275,\n",
       "       259, 284, 284, 252, 297, 290, 326, 274, 276, 277, 295, 287, 321,\n",
       "       274, 279, 292, 274, 323, 277, 292, 301, 264, 264, 280, 259, 299,\n",
       "       257, 288, 338, 281, 280, 276, 289, 252, 276, 235, 229, 259, 276,\n",
       "       290, 271, 335, 306, 259, 253, 267, 327, 300, 266, 290, 309, 301,\n",
       "       285, 290, 275, 329, 288, 256, 287, 269, 268, 287, 258, 297, 300,\n",
       "       252, 310, 297, 334, 289, 278, 302, 263, 263, 288, 278, 285, 285,\n",
       "       247, 315, 264, 276, 322, 313, 272, 296, 277, 320, 237, 264, 290,\n",
       "       272, 267, 244, 339, 268, 283, 341, 269, 283, 291, 272, 263, 273,\n",
       "       290, 228, 263, 254, 292, 308, 320, 302, 262, 302, 331, 278, 290,\n",
       "       272, 311, 269, 304, 288, 337, 356, 315, 287, 288, 315, 268, 253,\n",
       "       261, 276, 261, 286, 259, 280, 294, 276, 312, 288, 279, 318, 294,\n",
       "       279, 261, 272, 232, 297, 244, 320, 272, 281, 294, 309, 334, 303,\n",
       "       265, 281, 268, 315, 323, 288, 332, 298, 298, 257, 282, 283, 267,\n",
       "       292, 289, 297, 253, 315, 320, 287, 267, 272, 284, 310, 296, 317,\n",
       "       329, 246, 284, 261, 284, 244, 248, 322, 328, 286, 303, 352, 315,\n",
       "       258, 286, 256, 277, 287, 321, 303, 273, 257, 274, 269, 279, 306,\n",
       "       355, 255, 268, 298, 281, 264, 253, 245, 279, 267, 291, 270, 320,\n",
       "       332, 264, 287, 314, 297, 279, 277, 251, 281, 321, 291, 266, 305,\n",
       "       281, 240, 279, 316, 295, 283, 300, 277, 289, 306, 272, 252, 353,\n",
       "       281, 258, 272, 280, 265, 272, 296, 271, 280, 294, 290, 384, 283,\n",
       "       244, 271, 298, 260, 297, 283, 276, 325, 262, 288, 252, 298, 296,\n",
       "       322, 306, 300])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dead_filter_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e37d51e7-5835-489e-8b85-716ecf4eb20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  12,  14,  17,  20,  22,  23,  26,  30,  31,  32,  36,  37,\n",
       "        39,  47,  50,  51,  56,  59,  60,  62,  63,  65,  67,  74,  76,\n",
       "        78,  87,  92,  93,  99, 100, 101, 102, 107, 108, 112, 113, 115,\n",
       "       118, 122, 123, 125, 126, 127, 128, 129, 133, 135, 137, 138, 139,\n",
       "       141, 148, 149, 153, 155, 157, 158, 159, 160, 164, 165, 167, 168,\n",
       "       172, 179, 181, 183, 184, 186, 187, 189, 191, 193, 195, 197, 204,\n",
       "       208, 210, 211, 214, 215, 220, 224, 232, 236, 238, 243, 245, 248,\n",
       "       249, 250, 251, 257, 262, 263, 265, 266, 268, 270, 271, 274, 275,\n",
       "       277, 280, 294, 302, 303, 304, 305, 306, 307, 309, 310, 312, 314,\n",
       "       316, 319, 322, 323, 325, 327, 328, 329, 331, 334, 335, 337, 345,\n",
       "       347, 350, 351, 352, 353, 356, 360, 368, 370, 374, 376, 379, 381,\n",
       "       383, 384, 389, 392, 405, 406, 410, 411, 414, 415, 419, 427, 428,\n",
       "       430, 431, 432, 435, 443, 446, 447, 449, 451, 458, 461, 464, 472,\n",
       "       473, 474, 475, 477, 478, 482, 484, 486, 487, 488, 491, 500, 502,\n",
       "       505, 506, 511, 513, 516, 517, 518, 519, 523, 524, 526, 527, 528,\n",
       "       533, 535, 537, 538, 543, 544, 545, 546, 553, 554, 556, 557, 558,\n",
       "       564, 565, 571, 572, 575, 582, 584, 585, 588, 589, 594, 595, 597,\n",
       "       601, 602, 604, 607, 610, 617, 620, 622, 626, 628, 631, 635, 636,\n",
       "       637, 638, 639])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dead_filter_tmp > 290)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "779cad3c-b5e8-439c-96ae-8e9c5fb2cab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number filters')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.hist(dead_filter_tmp, 30, density=False, histtype='bar', facecolor='b',  alpha=0.5)\n",
    "plt.xlabel(\"Number dead filters in the Weight\")\n",
    "plt.ylabel(\"Number filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93b3b4c9-32b0-4e7b-9345-e551b412b3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([228, 229, 231, 232, 232, 235, 237, 238, 240, 241, 241, 241, 243,\n",
       "       243, 244, 244, 244, 244, 244, 245, 245, 246, 246, 246, 247, 247,\n",
       "       248, 248, 249, 249, 250, 251, 252, 252, 252, 252, 252, 252, 252,\n",
       "       252, 253, 253, 253, 253, 253, 254, 254, 254, 254, 254, 255, 255,\n",
       "       255, 255, 255, 256, 256, 256, 256, 256, 256, 257, 257, 257, 257,\n",
       "       257, 258, 258, 258, 258, 258, 258, 259, 259, 259, 259, 259, 259,\n",
       "       259, 259, 259, 259, 259, 260, 260, 261, 261, 261, 261, 261, 261,\n",
       "       261, 261, 261, 261, 262, 262, 262, 262, 262, 262, 262, 262, 263,\n",
       "       263, 263, 263, 263, 263, 263, 263, 263, 264, 264, 264, 264, 264,\n",
       "       264, 264, 264, 264, 264, 265, 265, 265, 265, 265, 265, 265, 266,\n",
       "       266, 266, 266, 266, 266, 266, 266, 266, 266, 266, 267, 267, 267,\n",
       "       267, 267, 267, 267, 267, 268, 268, 268, 268, 268, 268, 268, 268,\n",
       "       268, 268, 268, 268, 268, 269, 269, 269, 269, 269, 269, 269, 269,\n",
       "       269, 269, 269, 270, 270, 270, 270, 270, 270, 270, 270, 270, 271,\n",
       "       271, 271, 271, 271, 271, 271, 271, 271, 272, 272, 272, 272, 272,\n",
       "       272, 272, 272, 272, 272, 272, 272, 272, 272, 273, 273, 273, 273,\n",
       "       273, 273, 273, 273, 274, 274, 274, 274, 274, 274, 274, 275, 275,\n",
       "       275, 275, 275, 275, 275, 275, 276, 276, 276, 276, 276, 276, 276,\n",
       "       276, 276, 276, 276, 276, 276, 277, 277, 277, 277, 277, 277, 277,\n",
       "       277, 277, 277, 277, 277, 278, 278, 278, 278, 278, 278, 278, 279,\n",
       "       279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279,\n",
       "       280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 281,\n",
       "       281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281,\n",
       "       281, 281, 281, 282, 282, 282, 282, 283, 283, 283, 283, 283, 283,\n",
       "       283, 283, 283, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284,\n",
       "       285, 285, 285, 285, 285, 285, 285, 285, 285, 285, 286, 286, 286,\n",
       "       286, 286, 286, 286, 286, 286, 286, 286, 286, 287, 287, 287, 287,\n",
       "       287, 287, 287, 287, 287, 287, 287, 287, 287, 288, 288, 288, 288,\n",
       "       288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "       289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 290, 290,\n",
       "       290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290,\n",
       "       291, 291, 291, 291, 291, 291, 291, 292, 292, 292, 292, 292, 292,\n",
       "       293, 293, 293, 293, 294, 294, 294, 294, 294, 294, 294, 294, 295,\n",
       "       295, 295, 295, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
       "       296, 296, 296, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297,\n",
       "       297, 297, 297, 298, 298, 298, 298, 298, 298, 298, 298, 299, 299,\n",
       "       299, 299, 299, 300, 300, 300, 300, 300, 300, 300, 301, 301, 301,\n",
       "       301, 301, 301, 302, 302, 302, 302, 302, 302, 302, 303, 303, 303,\n",
       "       303, 303, 303, 304, 304, 304, 305, 305, 305, 305, 305, 305, 305,\n",
       "       306, 306, 306, 306, 306, 306, 306, 306, 306, 307, 307, 307, 307,\n",
       "       308, 309, 309, 309, 309, 310, 310, 310, 310, 311, 311, 311, 311,\n",
       "       311, 312, 312, 312, 313, 313, 313, 313, 314, 314, 314, 314, 314,\n",
       "       314, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 316, 316,\n",
       "       317, 317, 318, 318, 318, 318, 318, 319, 319, 320, 320, 320, 320,\n",
       "       320, 320, 320, 320, 320, 321, 321, 321, 322, 322, 322, 323, 323,\n",
       "       323, 323, 324, 324, 325, 325, 325, 326, 326, 327, 327, 328, 328,\n",
       "       329, 329, 329, 330, 330, 331, 331, 332, 332, 332, 333, 333, 333,\n",
       "       334, 334, 335, 337, 337, 338, 338, 339, 340, 340, 340, 341, 342,\n",
       "       346, 349, 351, 352, 353, 355, 355, 356, 356, 359, 360, 368, 368,\n",
       "       369, 371, 384])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(dead_filter_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3574fd27-7b6a-4ccc-8cc7-24544118377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.496875"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dead_filter_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc12c6fb-a030-4e4e-b129-21f7e2dc9e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(dead_filter_tmp, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc0f9f9-3a38-40d8-91bc-959037f3d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.shape:  (16, 3, 3, 3) \t dead_filter:  (0,)\n",
      "w.shape:  (160, 16, 3, 3) \t dead_filter:  (430,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (3359,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (301,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (91,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (1214,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (4,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (943,)\n",
      "w.shape:  (160, 160, 3, 3) \t dead_filter:  (0,)\n",
      "w.shape:  (320, 160, 3, 3) \t dead_filter:  (114,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (22,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (364,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (0,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (833,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (0,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (1197,)\n",
      "w.shape:  (320, 320, 3, 3) \t dead_filter:  (0,)\n",
      "w.shape:  (640, 320, 3, 3) \t dead_filter:  (884,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (20,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (14068,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (1848,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (45687,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (16213,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (39616,)\n",
      "w.shape:  (640, 640, 3, 3) \t dead_filter:  (183358,)\n"
     ]
    }
   ],
   "source": [
    "alive_filter_list = []\n",
    "dead_filter_list = []\n",
    "\n",
    "for i, m in enumerate(filter(lambda m: type(m) == torch.nn.Conv2d and m.kernel_size == (3, 3), model.modules())):\n",
    "    \n",
    "    w0 = (m.weight.detach().cpu().numpy().copy())\n",
    "    w = (m.weight.detach().cpu().numpy().reshape(-1, 9).copy())\n",
    "\n",
    "    t = np.abs(w).max() / 100    \n",
    "    cache = np.ones_like(w)\n",
    "    cache[np.abs(w) < t] = 0\n",
    "    dead_mask  = (cache.sum(axis=1) == 0)\n",
    "    alive_mask = (cache.sum(axis=1) != 0)\n",
    "\n",
    "    dead_filter = np.where(dead_mask == True)[0]\n",
    "    alive_filter = np.where(alive_mask == True)[0]\n",
    "    \n",
    "    dead_filter_list.append( (w0.shape, dead_filter) )\n",
    "    alive_filter_list.append( (w0.shape, alive_filter) )\n",
    "    print(\"w.shape: \", w0.shape, \"\\t dead_filter: \", dead_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51af755e-126e-4269-b494-65fb2a15ad66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alive_filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6fe419-ae97-4441-a7fe-752f781ceadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dead_filter_list, './../defenses/sparsity/wrn2810_dead.pkl'  , pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7650354e-cb24-4841-8bf8-6b0f6fffd111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(alive_filter_list, './../defenses/sparsity/wrn2810.pkl'  , pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06315c61-4c93-44b3-b076-30746f80de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_filter = torch.load('./../defenses/sparsity/wrn2810.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50c0e90-aa61-4fb8-b3ae-30733fdfe80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_filter[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e635d5c1-51b8-4070-8213-2d2c7f1686c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   137,    148,    155, ..., 409385, 409390, 409497])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dead_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e3b7a4-a8ca-4d48-bafb-227317ef1278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3686400,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1657d705-3ec3-4d7f-b4d5-753fec4f6483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183358, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[dead_filter].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9282cd6a-2515-4448-892d-ad87212008ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226242, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[alive_filter].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e89c12e-73ae-4e7f-a813-065182ad4e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409600, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ae4dc4-d7c2-48d3-a372-c4427ccbbfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409600, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9277c2f-7e42-4b47-a751-bd13effe6ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(18).reshape((2,3,3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a3d2085-dbe2-484d-be48-d0c22d666293",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = arr.reshape(-1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "772b05ad-5f44-47ec-b2a0-ce52c7df5693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f831c0b-cc93-4df9-a583-7d4513d6970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15cb70b3-a959-4147-a967-6fbdff3b6c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideResNet(\n",
      "  (init_conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Sequential(\n",
      "    (0): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (1): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (1): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): WideBasic(\n",
      "      (residual): Sequential(\n",
      "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "        (6): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f659b8d-6132-431f-9dd5-598cc79f4bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cuda--11-1-1--pytorch--1-9-0]",
   "language": "python",
   "name": "conda-env-.conda-cuda--11-1-1--pytorch--1-9-0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
